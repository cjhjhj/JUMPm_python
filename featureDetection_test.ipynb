{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import os, sys, re, pickle, utils, numpy as np, pandas as pd\n",
    "from pyteomics import mzxml\n",
    "from numpy.lib.recfunctions import append_fields\n",
    "\n",
    "\n",
    "def detectPeaks(spec, params):\n",
    "    # Parameters\n",
    "    if params[\"data_acquisition_mode\"] == \"1\":\n",
    "        isCentroided = 1\n",
    "    elif params[\"data_acquisition_mode\"] == \"2\":\n",
    "        isCentroided = 0\n",
    "    else:\n",
    "        print(\"Please set the proper 'data_acquisition_mode' parameter\")\n",
    "        sys.exit(\"\")\n",
    "    intensityThreshold = 0  # May come from a parameter file\n",
    "\n",
    "    # m/z and intensity arrays from a spectrum object\n",
    "    mzArray = spec[\"m/z array\"]\n",
    "    intensityArray = spec[\"intensity array\"]\n",
    "    nPeaks = len(mzArray)\n",
    "    newMzArray = np.array([])\n",
    "    newIntensityArray = np.array([])\n",
    "\n",
    "    # Detect peaks (i.e. centroidization of MS1 spectrum)\n",
    "    if isCentroided == 0:  # i.e. Profile mode MS1\n",
    "        for i in range(2, nPeaks - 2):\n",
    "            if intensityArray[i] > 0:\n",
    "                # Consider 2 points before and after the point of interest x, i.e. 5 point window\n",
    "                b2, b1, x, a1, a2 = intensityArray[(i - 2):(i + 3)]\n",
    "                if x >= intensityThreshold:\n",
    "                    if isMax(b2, b1, x, a1, a2):\n",
    "                        # If x is the local maximum in a 5-point window, lower and upper bounds for a peak will be explored\n",
    "                        # Refer Figure 1a and b in the paper, Cox and Mann, Nature Biotech. 2008; 26: 1367-22\n",
    "                        minInd = findMinPeakIndex(i, intensityArray)\n",
    "                        maxInd = findMaxPeakIndex(i, intensityArray)\n",
    "                        if (maxInd - minInd) > 2:\n",
    "                            newMz, newIntensity = findPeakCenter(minInd, i, maxInd, mzArray, intensityArray)\n",
    "                            newMzArray = np.append(newMzArray, newMz)\n",
    "                            newIntensityArray = np.append(newIntensityArray, newIntensity)\n",
    "\n",
    "        # Update \"spec\" object\n",
    "        spec[\"m/z array\"] = newMzArray\n",
    "        spec[\"intensity array\"] = newIntensityArray\n",
    "\n",
    "    # Do nothing for centroid mode MS1\n",
    "    return spec\n",
    "\n",
    "\n",
    "def isMax(b2, b1, x, a1, a2):\n",
    "    if x > b1 and x > a1:\n",
    "        return True\n",
    "    if x > b2 and x == b1 and x > a1:\n",
    "        return True\n",
    "    if x > b1 and x == a1 and x > a2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def findMinPeakIndex(ind, array):\n",
    "    while ind > 0 and array[ind] != 0 and array[ind - 1] <= array[ind]:\n",
    "        ind -= 1\n",
    "    return ind + 1\n",
    "\n",
    "\n",
    "def findMaxPeakIndex(ind, array):\n",
    "    count = len(array)\n",
    "    while ind < count and array[ind] != 0 and array[ind + 1] <= array[ind]:\n",
    "        ind += 1\n",
    "    return ind - 1\n",
    "\n",
    "\n",
    "def findPeakCenter(minInd, centerInd, maxInd, mz, intensity):\n",
    "    # Find the center of a peak composed of five data points\n",
    "    centerMz = 0\n",
    "    centerIntensity = 0\n",
    "    for i in range(minInd, maxInd + 1):\n",
    "        if intensity[i] >= centerIntensity:\n",
    "            centerIntensity = intensity[i]  # Take the maximum intensity as a peak intensity\n",
    "\n",
    "    # There\"s a plateau, bu others are zeros\n",
    "    if minInd == maxInd:\n",
    "        centerMz = mz[maxInd]\n",
    "        return centerMz, centerIntensity\n",
    "\n",
    "    # Right-angled triangle-shaped peak\n",
    "    if minInd == centerInd:\n",
    "        centerMz = estimate2(mz[centerInd], mz[centerInd + 1], intensity[centerInd], intensity[centerInd + 1])\n",
    "        return centerMz, centerIntensity\n",
    "\n",
    "    # Left-angled triangle-shaped peak\n",
    "    if maxInd == centerInd:\n",
    "        centerMz = estimate2(mz[centerInd - 1], mz[centerInd], intensity[centerInd - 1], intensity[centerInd])\n",
    "        return centerMz, centerIntensity\n",
    "\n",
    "    # Typical bell(triangle)-shaped peak\n",
    "    centerMz = estimate3(mz[centerInd - 1], mz[centerInd], mz[centerInd + 1], intensity[centerInd - 1],\n",
    "                         intensity[centerInd], intensity[centerInd + 1])\n",
    "    return centerMz, centerIntensity\n",
    "\n",
    "\n",
    "def estimate2(m1, m2, i1, i2):\n",
    "    centerVal = (m1 * i1 + m2 * i2) / (i1 + i2)  # Intensity-weighted average of m/z\n",
    "    return centerVal\n",
    "\n",
    "\n",
    "def estimate3(m1, m2, m3, i1, i2, i3):\n",
    "    l1 = np.log(i1)\n",
    "    l2 = np.log(i2)\n",
    "    l3 = np.log(i3)\n",
    "    centerVal = 0.5 * ((l1 - l2) * (m3 ** 2 - m1 ** 2) - (l1 - l3) * (m2 ** 2 - m1 ** 2)) / (\n",
    "            (l1 - l2) * (m3 - m1) - (l1 - l3) * (m2 - m1))\n",
    "    return centerVal\n",
    "\n",
    "\n",
    "def findPeakMatch(array, value, tolerance):\n",
    "    mzArray = np.asarray(array[\"m/z array\"])\n",
    "    ind = np.abs(mzArray - value).argmin()  # Index of the closest element to \"value\" in the array\n",
    "    difference = np.abs(mzArray[ind] - value) / value * 1e6\n",
    "    if difference <= tolerance:\n",
    "        return True, ind\n",
    "    else:\n",
    "        return False, 0\n",
    "\n",
    "\n",
    "def reduceMS1(spec, noise, array):\n",
    "    # Input\n",
    "    # spec: spectrum object read by pyteomics\n",
    "    # array: index of \"m/z array\" (and \"intensity array\") to be retained\n",
    "    array = array.astype(int)\n",
    "\n",
    "    # Noise level estimation\n",
    "    ind = np.setdiff1d(range(len(spec[\"m/z array\"])), array)\n",
    "    noiseLevel = np.percentile(spec[\"intensity array\"][ind], 25)    # 25 percentile = 1st quartile = median of bottom 50%\n",
    "    # noiseLevel = np.percentile([spec[\"intensity array\"][i] for i in ind], 25)   # 25 percentile = 1st quartile = median of bottom 50%\n",
    "    noise[spec[\"num\"]] = noiseLevel\n",
    "\n",
    "    # Reduce m/z array and intensity array of spec and replace\n",
    "    spec[\"m/z array\"] = spec[\"m/z array\"][array]\n",
    "    spec[\"intensity array\"] = spec[\"intensity array\"][array]\n",
    "    # rMz = [spec[\"m/z array\"][i] for i in array]\n",
    "    # rIntensity = [spec[\"intensity array\"][i] for i in array]\n",
    "    # spec[\"m/z array\"] = rMz\n",
    "    # spec[\"intensity array\"] = rIntensity\n",
    "\n",
    "    return spec, noise\n",
    "\n",
    "\n",
    "def getClosest(spec, mz, tol):\n",
    "    ind = np.argmin(abs(spec[\"m/z array\"] - mz))\n",
    "    diff = abs(mz - spec[\"m/z array\"][ind]) / mz * 1e6\n",
    "    if diff < tol:\n",
    "        return 1, ind\n",
    "    else:\n",
    "        return 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Extraction of MS1 spectra from IROA_IS_NEG_1.mzXML\n",
      "  Done\n",
      "  Feature detection \n",
      "  Progress: [####################] 100% Done...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n##################\\n# Filtering step #\\n##################\\n# A feature may contain multiple peaks from one scan\\n# In this case, one with the largest intensity is chosen\\ngMinRt, gMaxRt = 0, 0  # Global minimum and maximum RT over all features\\nfor i in range(len(f)):\\n    if len(f[i][\"num\"]) != len(list(set(f[i][\"num\"]))):\\n        temp = {}\\n        for j in range(len(f[i][\"num\"])):\\n            if f[i][\"num\"][j] in temp:\\n                currIntensity = f[i][\"intensity\"][j]\\n                if currIntensity > temp[f[i][\"num\"][j]][\"intensity\"]:\\n                    temp[f[i][\"num\"][j]][\"intensity\"] = currIntensity\\n                    temp[f[i][\"num\"][j]][\"index\"] = j\\n            else:\\n                temp[f[i][\"num\"][j]] = {}\\n                temp[f[i][\"num\"][j]][\"intensity\"] = f[i][\"intensity\"][j]\\n                temp[f[i][\"num\"][j]][\"index\"] = j\\n        uInd = []\\n        for key in sorted(temp.keys()):\\n            uInd.append(temp[key][\"index\"])\\n        f[i][\"mz\"] = [f[i][\"mz\"][u] for u in uInd]\\n        f[i][\"intensity\"] = [f[i][\"intensity\"][u] for u in uInd]\\n        f[i][\"num\"] = [f[i][\"num\"][u] for u in uInd]\\n        f[i][\"rt\"] = [f[i][\"rt\"][u] for u in uInd]\\n        f[i][\"index\"] = [f[i][\"index\"][u] for u in uInd]\\n\\n    if i == 0:\\n        gMinRt = min(f[i][\"rt\"])\\n        gMaxRt = max(f[i][\"rt\"])\\n    else:\\n        if min(f[i][\"rt\"]) < gMinRt:\\n            gMinRt = min(f[i][\"rt\"])\\n        if max(f[i][\"rt\"]) > gMaxRt:\\n            gMaxRt = max(f[i][\"rt\"])\\n\\n###################################\\n# Organization of output features #\\n###################################\\nn = 0\\nms1ToFeatures = {}\\nfor i in range(len(f)):\\n    # 1. mz: mean m/z of a feauture = weighted average of m/z and intensity\\n    mz = np.sum(np.multiply(f[i][\"mz\"], f[i][\"intensity\"])) / np.sum(f[i][\"intensity\"])\\n\\n    # 2. intensity: intensity of a feature (maximum intensity among the peaks consist of the feature)\\n    intensity = max(f[i][\"intensity\"])\\n\\n    # 3. z: charge of the feature, set to 1 now, but modified later\\n    z = 1\\n    isotope = 0  # Will be used later\\n\\n    # 4. RT: RT of the representative peak (i.e. strongest peak) of a feature\\n    ind = np.argmax(f[i][\"intensity\"])\\n    rt = f[i][\"rt\"][ind]\\n    if rt.unit_info == \"minute\":\\n        rt = rt * 60  # Convert to the unit of second\\n\\n    # 5. minRT and maxRT\\n    minRt = min(f[i][\"rt\"])\\n    maxRt = max(f[i][\"rt\"])\\n\\n    # 6. MS1 scan number of the representative peak of a feature\\n    ms1 = f[i][\"num\"][ind]\\n\\n    # 7. minMS1 and maxMS1\\n    minMs1 = min(f[i][\"num\"])\\n    maxMs1 = max(f[i][\"num\"])\\n\\n    # 8. SNratio (signal-to-noise ratio of the feature)\\n    if ms1 in noise:\\n        noiseLevel = noise[ms1]\\n    else:\\n        noiseLevel = 500\\n    snRatio = intensity / noiseLevel\\n    featureIntensityThreshold = noiseLevel * float(params[\"signal_noise_ratio\"])\\n\\n    if intensity >= featureIntensityThreshold:\\n        # 9. Percentage of true feature\\n        pctTF = (maxRt - minRt) / (gMaxRt - gMinRt) * 100\\n        # Organize features in a structured numpy array form\\n        if n == 0:\\n            features = np.array([(mz, intensity, z, rt, minRt, maxRt, ms1, minMs1, maxMs1, snRatio, pctTF, isotope)],\\n                                dtype=\"f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8\")\\n            n += 1\\n        else:\\n            features = np.append(features,\\n                                 np.array([(mz, intensity, z, rt, minRt, maxRt, ms1, minMs1, maxMs1, snRatio, pctTF,\\n                                            isotope)],\\n                                          dtype=features.dtype))\\n        for j in range(len(f[i][\"num\"])):\\n            num = f[i][\"num\"][j]\\n            if num not in ms1ToFeatures:\\n                ms1ToFeatures[num] = {\"mz\": [f[i][\"mz\"][j]],\\n                                      \"intensity\": [f[i][\"intensity\"][j]]}\\n            else:\\n                ms1ToFeatures[num][\"mz\"].append(f[i][\"mz\"][j])\\n                ms1ToFeatures[num][\"intensity\"].append(f[i][\"intensity\"][j])\\n    else:\\n        continue\\n\\nfeatures.dtype.names = (\\n\"mz\", \"intensity\", \"z\", \"RT\", \"minRT\", \"maxRT\", \"MS1\", \"minMS1\", \"maxMS1\", \"SNratio\", \"PercentageTF\", \"isotope\")\\n\\n##########################\\n# Decharging of features #\\n##########################\\nfeatures = np.sort(features, order=\"intensity\")[::-1]  # Sort features in descending order of intensity\\ndelC = 1.00335  # Mass difference between 13C and 12C\\ntolPpm = 10  # Tolerance for decharging\\nmaxCharge = 6\\nfor i in range(features.shape[0]):\\n    mz = features[\"mz\"][i]\\n    intensity = features[\"intensity\"][i]\\n    lL = mz - mz * tolPpm / 1e6\\n    uL = delC + mz + mz * tolPpm / 1e6\\n    scan = features[\"MS1\"][i]\\n    ind = np.where((features[\"MS1\"] > (scan - 50)) & (features[\"MS1\"] < (scan + 50)))[0]\\n    charge = 0\\n    for j in ind:\\n        if j == i:\\n            continue\\n        else:\\n            mz_j = features[\"mz\"][j]\\n            intensity_j = features[\"intensity\"][j]\\n            # A presumable isotopic peak intensity should be greater than 20% of feature intensity (to prevent the inclusion of small/noisy peaks)\\n            # and smaller than 500% (i.e. inverse of 20%) of feature intensity (to prevent that a monoisotopic peak is merged for decharging of a small/noisy peak)\\n            # if lL <= mz_j < uL and (0.2 * intensity) <= intensity_j < (5 * intensity):\\n            if lL <= mz_j < uL:\\n                # Look for potential isotopic peak and decharge\\n                diff = np.around(1 / abs(mz - mz_j)).astype(int)\\n                if diff == 0 or diff > maxCharge:\\n                    continue\\n                dev = abs(abs(mz - mz_j) - (delC / diff))\\n                if dev > (mz * tolPpm / 1e6):\\n                    continue\\n                else:\\n                    charge = diff\\n                    if intensity > intensity_j:\\n                        features[\"isotope\"][j] = 1\\n                    break\\n            else:\\n                continue\\n    features[\"z\"][i] = charge\\n\\n# Remove the features from isotopic peaks\\nind = np.where(features[\"isotope\"] == 1)[0]\\nfeatures = np.delete(features, ind)\\nprint()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramFile = r\"C:\\Research\\Projects\\7Metabolomics\\JUMPm\\IROAsamples\\jumpm_negative_desktop.params\"\n",
    "inputFile = r\"C:\\Research\\Projects\\7Metabolomics\\JUMPm\\IROAsamples\\IROA_IS_NEG_1.mzXML\"\n",
    "\n",
    "##############\n",
    "# Parameters #\n",
    "##############\n",
    "params = utils.getParams(paramFile)\n",
    "firstScan = int(params[\"first_scan_extraction\"])\n",
    "lastScan = int(params[\"last_scan_extraction\"])\n",
    "gap = int(params[\"skipping_scans\"])\n",
    "scanWindow = gap + 1\n",
    "matchPpm = float(params[\"mass_tolerance_peak_matching\"])\n",
    "\n",
    "##################\n",
    "# Initialization #\n",
    "##################\n",
    "reader = mzxml.read(inputFile)\n",
    "f = []  # Feature array\n",
    "nFeatures = -1\n",
    "cache = []\n",
    "noise = {}  # Empty dictionary for noise level information\n",
    "oldMinInd = -1\n",
    "oldMaxInd = -1\n",
    "\n",
    "ms = []\n",
    "with reader:\n",
    "    ############################\n",
    "    # Get MS1 scan information #\n",
    "    ############################\n",
    "    msCount = 0\n",
    "    filename = os.path.basename(inputFile)\n",
    "    print(\"  Extraction of MS1 spectra from %s\" % filename)\n",
    "    for spec in reader:\n",
    "        msLevel = int(spec[\"msLevel\"])\n",
    "        scanNum = int(spec[\"num\"])\n",
    "        if msLevel == 1 and firstScan <= scanNum <= lastScan:\n",
    "            ms.append(spec)\n",
    "            msCount += 1\n",
    "        elif scanNum > lastScan:\n",
    "            break\n",
    "    print(\"  Done\")\n",
    "\n",
    "################################\n",
    "# Feature (3D-peak) generation #\n",
    "################################\n",
    "print(\"  Feature detection \")\n",
    "progress = utils.progressBar(msCount)\n",
    "for i in range(msCount):\n",
    "    progress.increment()\n",
    "    minInd = max(0, i - gap - 1)\n",
    "    maxInd = min(msCount - 1, i + gap + 1)\n",
    "    if i == 0:\n",
    "        for j in range(maxInd + 1):\n",
    "            spec = detectPeaks(ms[j], params)\n",
    "            spec[\"index\"] = j\n",
    "            cache.append(spec)\n",
    "    else:\n",
    "        for j in range(oldMinInd, minInd):\n",
    "            cache.pop(0)  # Remove the first element in cache\n",
    "        for j in range(oldMaxInd + 1, maxInd + 1):\n",
    "            spec = detectPeaks(ms[j], params)\n",
    "            spec[\"index\"] = j\n",
    "            cache.append(spec)\n",
    "\n",
    "    ##################\n",
    "    # Reduction step #\n",
    "    ##################\n",
    "    p = cache[i - minInd]\n",
    "    pCount = len(p[\"m/z array\"])\n",
    "    valids = np.array([])\n",
    "    count = 0\n",
    "    for j in range(pCount):\n",
    "        cm = p[\"m/z array\"][j]\n",
    "        match = 0\n",
    "        nTry = 0\n",
    "        # Backward search\n",
    "        for k in range(i - 1, minInd - 1, -1):\n",
    "            q = cache[k - minInd]\n",
    "            match, ind = getClosest(q, cm, matchPpm)\n",
    "            if match == 1:\n",
    "                break\n",
    "            nTry += 1\n",
    "            if nTry > scanWindow:\n",
    "                break\n",
    "        if match == 0:  # Forward search\n",
    "            nTry = 0\n",
    "            for k in range(i + 1, maxInd + 1):\n",
    "                q = cache[k - minInd]\n",
    "                match, ind = getClosest(q, cm, matchPpm)\n",
    "                if match == 1:\n",
    "                    break\n",
    "                nTry += 1\n",
    "                if nTry > scanWindow:\n",
    "                    break\n",
    "        if match == 1:\n",
    "            valids = np.append(valids, j)\n",
    "\n",
    "    # Peak reduction and noise-level estimation\n",
    "    p, noise = reduceMS1(p, noise, valids)\n",
    "\n",
    "    #####################\n",
    "    # Peak merging step #\n",
    "    #####################\n",
    "    cache[i - minInd] = p\n",
    "    pCount = len(p[\"m/z array\"])\n",
    "    for j in range(pCount):\n",
    "        cm = p[\"m/z array\"][j]\n",
    "        match = 0\n",
    "        nTry = 0\n",
    "        matchedPeakInd = []\n",
    "        # Backward search\n",
    "        for k in range(i - 1, minInd - 1, -1):\n",
    "            q = cache[k - minInd]\n",
    "            matchIndicator, ind = getClosest(q, cm, matchPpm)\n",
    "            # $matchIndicator = 1 means that the j-th (reduced) peak in the i-th scan\n",
    "            # can form a 3D-peak with $ind-th (reduced) peak in the previous scan (%q)\n",
    "            if matchIndicator == 1:\n",
    "                matchedPeakInd.append(q[\"featureIndex\"][ind])\n",
    "                match = 1\n",
    "        if match == 1:\n",
    "            matchedPeakInd = list(set(matchedPeakInd))  # Make the list unique\n",
    "            fInd = None\n",
    "            if len(matchedPeakInd) > 1:  # There are multiple matches to the peaks in previous scans\n",
    "                fInd = min(matchedPeakInd)\n",
    "                for m in matchedPeakInd:\n",
    "                    # Merge to the lowest indexed feature and remove the \"merged\" features\n",
    "                    if m != fInd:\n",
    "                        f[fInd][\"mz\"].extend(f[m][\"mz\"])\n",
    "                        f[fInd][\"intensity\"].extend(f[m][\"intensity\"])\n",
    "                        f[fInd][\"num\"].extend(f[m][\"num\"])\n",
    "                        f[fInd][\"rt\"].extend(f[m][\"rt\"])\n",
    "                        f[fInd][\"index\"].extend(f[m][\"index\"])\n",
    "\n",
    "                        # Revise cache array\n",
    "                        for s in f[m][\"index\"]:\n",
    "                            for t in range(len(cache)):\n",
    "                                if cache[t][\"index\"] == s:\n",
    "                                    for u in range(len(cache[t][\"featureIndex\"])):\n",
    "                                        if cache[t][\"featureIndex\"][u] == m:\n",
    "                                            cache[t][\"featureIndex\"][u] = fInd\n",
    "                        f[m] = None  # Keep the size of feature array\n",
    "            else:\n",
    "                fInd = matchedPeakInd[0]\n",
    "            if \"featureIndex\" in cache[i - minInd]:\n",
    "                cache[i - minInd][\"featureIndex\"].append(fInd)\n",
    "            else:\n",
    "                cache[i - minInd][\"featureIndex\"] = [fInd]\n",
    "            f[fInd][\"mz\"].append(p[\"m/z array\"][j])\n",
    "            f[fInd][\"intensity\"].append(p[\"intensity array\"][j])\n",
    "            f[fInd][\"num\"].append(p[\"num\"])\n",
    "            f[fInd][\"rt\"].append(p[\"retentionTime\"])\n",
    "            f[fInd][\"index\"].append(p[\"index\"])\n",
    "\n",
    "            # print(\"feature #%d merges the peak of %f in %s\" % (fInd, p[\"m/z array\"][j], p[\"num\"]))\n",
    "\n",
    "        if match != 1:\n",
    "            if i < msCount:\n",
    "                nFeatures += 1\n",
    "                if \"featureIndex\" in cache[i - minInd]:\n",
    "                    cache[i - minInd][\"featureIndex\"].append(nFeatures)\n",
    "                else:\n",
    "                    cache[i - minInd][\"featureIndex\"] = [nFeatures]\n",
    "                f.append({\"mz\": [p[\"m/z array\"][j]],\n",
    "                          \"intensity\": [p[\"intensity array\"][j]],\n",
    "                          \"num\": [p[\"num\"]],\n",
    "                          \"rt\": [p[\"retentionTime\"]],\n",
    "                          \"index\": [i]})\n",
    "\n",
    "                # print(\"feature #%d is created from the peak of %f in %s\" % (nFeatures, p[\"m/z array\"][j], p[\"num\"]))\n",
    "\n",
    "    oldMinInd = minInd\n",
    "    oldMaxInd = maxInd\n",
    "\n",
    "# # For development purpose #########################\n",
    "# with open(\"featureDetection.pickle\", \"rb\") as file:\n",
    "#     vars = pickle.load(file)\n",
    "#     f = vars[0]\n",
    "#     params = vars[1]\n",
    "#     noise = vars[2]\n",
    "# ###################################################\n",
    "\n",
    "# Remove empty features\n",
    "f = [i for i in f if i is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Filtering step #\n",
    "##################\n",
    "# A feature may contain multiple peaks from one scan\n",
    "# In this case, one with the largest intensity is chosen\n",
    "gMinRt, gMaxRt = 0, 0  # Global minimum and maximum RT over all features\n",
    "for i in range(len(f)):\n",
    "    if len(f[i][\"num\"]) != len(list(set(f[i][\"num\"]))):\n",
    "        temp = {}\n",
    "        for j in range(len(f[i][\"num\"])):\n",
    "            if f[i][\"num\"][j] in temp:\n",
    "                currIntensity = f[i][\"intensity\"][j]\n",
    "                if currIntensity > temp[f[i][\"num\"][j]][\"intensity\"]:\n",
    "                    temp[f[i][\"num\"][j]][\"intensity\"] = currIntensity\n",
    "                    temp[f[i][\"num\"][j]][\"index\"] = j\n",
    "            else:\n",
    "                temp[f[i][\"num\"][j]] = {}\n",
    "                temp[f[i][\"num\"][j]][\"intensity\"] = f[i][\"intensity\"][j]\n",
    "                temp[f[i][\"num\"][j]][\"index\"] = j\n",
    "        uInd = []\n",
    "        for key in sorted(temp.keys()):\n",
    "            uInd.append(temp[key][\"index\"])\n",
    "        f[i][\"mz\"] = [f[i][\"mz\"][u] for u in uInd]\n",
    "        f[i][\"intensity\"] = [f[i][\"intensity\"][u] for u in uInd]\n",
    "        f[i][\"num\"] = [f[i][\"num\"][u] for u in uInd]\n",
    "        f[i][\"rt\"] = [f[i][\"rt\"][u] for u in uInd]\n",
    "        f[i][\"index\"] = [f[i][\"index\"][u] for u in uInd]\n",
    "\n",
    "    if i == 0:\n",
    "        gMinRt = min(f[i][\"rt\"])\n",
    "        gMaxRt = max(f[i][\"rt\"])\n",
    "    else:\n",
    "        if min(f[i][\"rt\"]) < gMinRt:\n",
    "            gMinRt = min(f[i][\"rt\"])\n",
    "        if max(f[i][\"rt\"]) > gMaxRt:\n",
    "            gMaxRt = max(f[i][\"rt\"])\n",
    "\n",
    "###################################\n",
    "# Organization of output features #\n",
    "###################################\n",
    "n = 0\n",
    "ms1ToFeatures = {}\n",
    "for i in range(len(f)):\n",
    "    # 1. mz: mean m/z of a feauture = weighted average of m/z and intensity\n",
    "    mz = np.sum(np.multiply(f[i][\"mz\"], f[i][\"intensity\"])) / np.sum(f[i][\"intensity\"])\n",
    "\n",
    "    # 2. intensity: intensity of a feature (maximum intensity among the peaks consist of the feature)\n",
    "    intensity = max(f[i][\"intensity\"])\n",
    "\n",
    "    # 3. z: charge of the feature, set to 1 now, but modified later\n",
    "    z = 1\n",
    "    isotope = 0  # Will be used later\n",
    "\n",
    "    # 4. RT: RT of the representative peak (i.e. strongest peak) of a feature\n",
    "    ind = np.argmax(f[i][\"intensity\"])\n",
    "    rt = f[i][\"rt\"][ind]\n",
    "    if rt.unit_info == \"minute\":\n",
    "        rt = rt * 60  # Convert to the unit of second\n",
    "\n",
    "    # 5. minRT and maxRT\n",
    "    minRt = min(f[i][\"rt\"])\n",
    "    maxRt = max(f[i][\"rt\"])\n",
    "\n",
    "    # 6. MS1 scan number of the representative peak of a feature\n",
    "    ms1 = f[i][\"num\"][ind]\n",
    "\n",
    "    # 7. minMS1 and maxMS1\n",
    "    minMs1 = min(f[i][\"num\"])\n",
    "    maxMs1 = max(f[i][\"num\"])\n",
    "\n",
    "    # 8. SNratio (signal-to-noise ratio of the feature)\n",
    "    if ms1 in noise:\n",
    "        noiseLevel = noise[ms1]\n",
    "    else:\n",
    "        noiseLevel = 500\n",
    "    snRatio = intensity / noiseLevel\n",
    "    featureIntensityThreshold = noiseLevel * float(params[\"signal_noise_ratio\"])\n",
    "\n",
    "    if intensity >= featureIntensityThreshold:\n",
    "        # 9. Percentage of true feature\n",
    "        pctTF = (maxRt - minRt) / (gMaxRt - gMinRt) * 100\n",
    "        # Organize features in a structured numpy array form\n",
    "        if n == 0:\n",
    "            features = np.array([(mz, intensity, z, rt, minRt, maxRt, ms1, minMs1, maxMs1, snRatio, pctTF, isotope)],\n",
    "                                dtype=\"f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8, f8\")\n",
    "            n += 1\n",
    "        else:\n",
    "            features = np.append(features,\n",
    "                                 np.array([(mz, intensity, z, rt, minRt, maxRt, ms1, minMs1, maxMs1, snRatio, pctTF,\n",
    "                                            isotope)],\n",
    "                                          dtype=features.dtype))\n",
    "        for j in range(len(f[i][\"num\"])):\n",
    "            num = f[i][\"num\"][j]\n",
    "            if num not in ms1ToFeatures:\n",
    "                ms1ToFeatures[num] = {\"mz\": [f[i][\"mz\"][j]],\n",
    "                                      \"intensity\": [f[i][\"intensity\"][j]]}\n",
    "            else:\n",
    "                ms1ToFeatures[num][\"mz\"].append(f[i][\"mz\"][j])\n",
    "                ms1ToFeatures[num][\"intensity\"].append(f[i][\"intensity\"][j])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "features.dtype.names = (\n",
    "\"mz\", \"intensity\", \"z\", \"RT\", \"minRT\", \"maxRT\", \"MS1\", \"minMS1\", \"maxMS1\", \"SNratio\", \"PercentageTF\", \"isotope\")\n",
    "\n",
    "##########################\n",
    "# Decharging of features #\n",
    "##########################\n",
    "features = np.sort(features, order=\"intensity\")[::-1]  # Sort features in descending order of intensity\n",
    "delC = 1.00335  # Mass difference between 13C and 12C\n",
    "tolPpm = 10  # Tolerance for decharging\n",
    "maxCharge = 6\n",
    "for i in range(features.shape[0]):\n",
    "    mz = features[\"mz\"][i]\n",
    "    intensity = features[\"intensity\"][i]\n",
    "    lL = mz - mz * tolPpm / 1e6\n",
    "    uL = delC + mz + mz * tolPpm / 1e6\n",
    "    scan = features[\"MS1\"][i]\n",
    "    ind = np.where((features[\"MS1\"] > (scan - 50)) & (features[\"MS1\"] < (scan + 50)))[0]\n",
    "    charge = 0\n",
    "    for j in ind:\n",
    "        if j == i:\n",
    "            continue\n",
    "        else:\n",
    "            mz_j = features[\"mz\"][j]\n",
    "            intensity_j = features[\"intensity\"][j]\n",
    "            # A presumable isotopic peak intensity should be greater than 20% of feature intensity (to prevent the inclusion of small/noisy peaks)\n",
    "            # and smaller than 500% (i.e. inverse of 20%) of feature intensity (to prevent that a monoisotopic peak is merged for decharging of a small/noisy peak)\n",
    "            # if lL <= mz_j < uL and (0.2 * intensity) <= intensity_j < (5 * intensity):\n",
    "            if lL <= mz_j < uL:\n",
    "                # Look for potential isotopic peak and decharge\n",
    "                diff = np.around(1 / abs(mz - mz_j)).astype(int)\n",
    "                if diff == 0 or diff > maxCharge:\n",
    "                    continue\n",
    "                dev = abs(abs(mz - mz_j) - (delC / diff))\n",
    "                if dev > (mz * tolPpm / 1e6):\n",
    "                    continue\n",
    "                else:\n",
    "                    charge = diff\n",
    "                    if intensity > intensity_j:\n",
    "                        features[\"isotope\"][j] = 1\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "    features[\"z\"][i] = charge\n",
    "\n",
    "# Remove the features from isotopic peaks\n",
    "ind = np.where(features[\"isotope\"] == 1)[0]\n",
    "features = np.delete(features, ind)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.txt\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
